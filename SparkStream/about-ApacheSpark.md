# Apache Spark
- 인메모리 기반의 대용량 데이터 고속처리 엔진으로, 범용 분산 클러스터 컴퓨팅 프레임워크
- 참고글: https://wikidocs.net/book/2350

## 등장배경
- 빅데이터 개념이 등장한 이후, HDFS를 기반으로 하는 하둡 에코시스템이 대세가 되었음
- 그러나 하둡 HDFS는 disk i/o를 기반으로 동작하여 실시간성 데이터 처리에 차질이 있었음
- 이 때 인메모리상에서 동작하여 반복적인 처리가 필요한 작업에서 하둡보다 최소 1,000배 이상 빠른 아파치 스파크 등장

## 특징
- Speed
    - 인메모리(In-Memory) 기반의 빠른 처리
- Ease of Use
    - Scala, Java, Python, R, SQL 등의 다양한 언어 기반의 고수준 API 사용 가능
- Generality
    - SQL, Streaming, 머신러닝, 그래프 연산 등 다양한 컴포넌트 제공
- Run Everywhere
    - YARN, Mesos, Kubernetes 등 다양한 클러스터에서 동작 가능
    - HDFS, Casandra, HBase 등 다양한 파일 포맷 지원
    - Kafka, Hadoop과 연계 가능한 확장성
    - SQL 기능을 담당하는 Spark SQL, 실시간 데이터 처리를 지원하는 Spark Streaming, 머신러닝 기능을 제공하는 MLib 등 다양한 라이브러리를 제공
    - 카프카, 플럼, 키네시스, TCP 소켓 등 다양한 경로로부터 데이터를 입력받고, map, reduce, window 등의 연산을 통해 데이터를 분석 후, 최종적으로 파일시스템, 데이터베이스 등에 적재됨

## 컴포넌트 구성
- 스파크 컴포넌트 구성은 스파크 라이브러리, 스파크 코어, 클러스터 매니저로 구분되어 있음

#### 스파크 코어
- Spark Core는 메인 컴포넌트로 작업 스케줄링, 메모리 관리, 장애 복구와 같은 기본적인 기능을 제공하고, RDD, Dataset, DataFrame을 이용한 스파크 연산 처리

#### 스파크 라이브러리
- 빅데이터 처리를 위한 작업용 라이브러리
- Spark SQL: SQL을 이용하여 RDD, DataSet, DataFrame 작업을 생성하고 처리
- Spark Streaming: 실시간 데이터 스트림을 처리하는 컴포넌트. 스트림 데이터를 작은 사이즈로 쪼개어 RDD처럼 처리
- MLib: 머신러닝 기능을 제공하는 컴포넌트로, 분류, 회귀, 클러스터링, 협업 필터링 등의 머신러닝 알고리즘과 모델평가 및 외부 데이터 불러오기 같은 기능 지원
- GraphX: 분산형 그래프 프로세싱이 가능하게 해주는 컴포넌트



## 버전별 특징

#### Spark v1
- 2014년 정식 발표
- RDD를 이용한 인메모리 방식으로 빠른 속도로 처리 가능
- v1.3에서 데이터프레임 추가
    - 프로젝트 텅스텐
- v1.6에서 데이터셋 추가
    - 데이터 타입체크
    - 인코더
    - 카탈리스트 옵티마이저 지원

#### Spark v2
- 2016년 발표
- RDD의 기능을 개선한 데이터프레임과 데이터셋을 통합
- 데이터를 스키마 형태로 추상화하여 제공
- 쿼리 최적화 기능 추가 

#### Spark v3
- 2019년 12월 발표
- 파이썬, 스칼라 2.12, JDK 11 지원
- 딥러닝 지원 강화
    - GPU 지원 추가
- 바이너리 파일 지원
- 쿠버네티스 지원 강화
- 다이나믹 파티션 프루닝(DPP) 지원하여 SQL 지원 강화


## 스파크 애플리케이션
- 스파크 실팽 프로그램으로 드라이버와 엑세큐터 프로세스로 실행되는 프로그램
- 클러스터 매니저가 스파크 애플리케이션의 리소스를 효율적으로 배분하게 됨

#### 드라이버 Driver
- 스파크 애플리케이션을 실행하는 프로세스
- main 함수를 실행하고 스파크 컨텍스트(SparkContext) 객체를 생성

#### 엑세큐터 Executor
- 태스크 실행을 담당하는 에이전트로 실제 작업을 진행하는 프로세스
- YARN의 컨테이너라고 볼 수 있음
- 엑세큐터는 태스크 단위로 작업을 실행하고 결과를 드라이버에게 알려줌
- 하나의 엑세큐터가 여러 개의 태스크를 동시에 실행할 수 있음
- 하나의 엑세큐터에 태스크가 너무 많으면 성능이 떨어지고, 너무 적으면 JVM을 공유하는 장점이 사라짐. 따라서 적절한 설정이 필요
    - 엑세큐터 개수
    - 엑세큐터가 사용할 메모리
    - 애플리케이션에 사용할 코어 개수
    - 메모리 오버헤드 비율
    - JVM 옵션

#### 태스크 Task
- 엑세큐터에서 실행되는 실제 작업
- 엑세큐터의 캐시를 공유해서 작업의 속도를 높일 수 있음


## 스파크 잡의 구성

#### 잡 Job
- 스파크 애플리케이션으로 제출된 작업

#### 스테이지 Stage
- 잡을 작업의 단위에 따라 구분한 것

#### 태스크 Task
- 엑세큐터에서 실행되는 실제 작업
- 데이터를 읽거나 필터링하는 등의 작업


## 스파크 스트리밍

#### 디스트림 DStream; Distretized stream 이산 스트림
- 스파크 스트리밍은 실시간 데이터 분석을 위한 스파크 컴포넌트
- 추상화 개념의 작은 배치 단위
- 데이터는 카프카, 플럼, 키네시스, TCP 소켓등 다양한 경로를 통해 입력받고 `map`, `reduce`, `window` 등의 연산을 통해 데이터를 분석하여 최종적으로 파일시스템, 데이터베이스 등에 적재하거나 스파크의 머신러닝, 그래프 컴포넌트에 이용

- 디스트림은 시간별로 도착한 데이터들의 연속적 모임
- 각 디스트림은 시간별 RDD들의 집합으로 구성
