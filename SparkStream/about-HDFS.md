# HDFS
- Hadoop Distributed File System; 하둡 분산 파일 시스템
- 하둡의 주요 모듈 중 하나로, 여러 서버를 하나의 서버처럼 묶어서 데이터를 분산하여 저장
- 실시간 처리보다는 배치처리를 위해 설계되어, 빠른 데이터 응답시간이 필요한 작업에는 적합하지 않음
- 네임노드가 단일 실패 지점(SPOF)이 되기 때문에 네임노드 관리가 중요


## HDFS의 노드
- name node: 메타 데이터만 저장
- data node: 파일 블록을 저장

#### name node와 메타데이터
- 네임노드
    - 네임노드의 주요역할은 메타데이터 관리와 데이터노드의 관리
    - 각 데이터노드에서 전달하는 메타데이터를 받아서 전체 노드의 메타데이터 정보와 파일정보를 묶어서 관리

- 메타데이터
    - 파일이름, 파일크기, 파일생성시간, 파일접근권한, 파일 소유자 및 그룹 소유자, 파일이 위치한 블록의 정보 등으로 구성

- 메타데이터 파일 종류
    - Fsimage 파일: 네임스페이스와 블록정보
    - Edits 파일: 파일의 생성, 삭제에 대한 트랜잭션 로그
    - 메모리에 저장하다가 주기적으로 파일로 생성
    - 파일 저장 위치는 사용자가 설정(dfs.name.dir)

- 메타데이터 내용
    - VERSION: 현재 실행중인 HDFS의 ID, 타입 등의 정보
    - edits_0000xxx-0000xxx: 트랜잭션 정보. edits_트랜잭션시작번호-트랜잭션종료번호
    - edits_inprogress_000xx: 최신 트랜잭션 정보. 압축되지 않은 정보
    - fsimage_000xxx: 000xxx까지 트랜잭션 정보가 처리된 fsimage
    - fsimage_000xxx.md5: fsimage의 해쉬값
    - seen_txid: 현재 트랜잭션 ID


## HDFS의 특징
- 블록 단위 저장
    - 기본 크기는 128MB
    - 블록사이즈보다 작은 파일은 기존 파일의 사이즈로 저장
    - 블록 사이즈보다 큰 크기의 데이터파일은 블록 단위로 나누어 저장 -> 단일 디스크의 데이터보다 큰 파일도 저장 가능
- 읽기 중심
    - HDFS는 데이터를 여러 번 읽는 것을 목적으로 하므로, 파일의 수정은 지원하지 않음
    - 파일 수정을 제한함으로써 동작이 단순화되고 데이터 리딩 속도가 빨라짐
- 블록 복제를 이용한 장애 복구
    - HDFS는 장애 복구를 위해 각 블록을 복제하여 저장
    - 기본 복제 단위는 3, 즉 하나의 블록은 3개의 블록으로 복제됨. 이런 경우 replica가 3이라고 표현
    - 따라서 1G 데이터를 저장할 때 필요한 저장공간은 3G
    - 복제된 데이터는 같은 랙(Rack)의 서버와 다른 랙의 서버로 저장
    - 파일 블록이 저장된 위치는 name node에 저장되어 있기 때문에 name node가 손상되면 HDFS를 이용할 수 없음.
    - 따라서 name node는 2개 이상으로 두는 것이 관례
- 데이터 지역성
    - 맵리듀스는 HDFS의 데이터 지역성을 이용해서 처리속도 증가
    - 처리 알고리즘이 있는 곳에 데이터를 이동시키지 않고, 데이터가 있는 곳에서 알고리즘을 처리
    - 네트워크를 통해 대용량 데이터를 이동시키는 비용을 줄일 수 있음
