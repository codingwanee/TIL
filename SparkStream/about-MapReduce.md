# 맵리듀스
- 간단한 단위작업을 반복하여 처리할 때 사용하는 프로그래밍 모델
- 맵리듀스 작업은 맵과 리듀스로 나누어져 처리되며, 병렬처리가 가능하여 여러 컴퓨터에서 동시에 처리하며 속도를 높일 수 있다
    - Map: 간단한 단위작업을 처리하는 단계
    - Reduce: 맵 작업의 결과물을 모아서 집계하는 단계

## 맵리듀스 작업 단위
- 하둡 v1의 작업 단위는 잡(job)이고, 하둡v2의 작업 단위는 애플리케이션(application)으로 이름은 변경되었으나 동일하게 관리됨
- 잡은 맵 태스크와 리듀스 태스크로 나뉘어지고, 태스크는 어템프트(attempt) 단위로 실행
- 하둡 잡이 생성되면 아이디가 job_xxx_xxx로 생성 / YARN에서는 application_xxx_xxx로 생성 / 접두어만 다를 뿐 같은 작업
- 잡에서 생성되는 맵태스크와 리듀스태스크는 attempt 접두어를 가지고 생성: attempt_xxx_xxx_m(r)_000000_0

## 맵리듀스 장애극복(failover)
- 맵리듀스 실행 중 오류가 발생하면 설정된 횟수만큼 자동으로 반복
    - 맵 반복설정: mapreduce.map.maxattempts
    - 리듀스 반복설정: mapreduce.reduce.maxattemtps
    - 디폴트는 3회로 설정되어 있음
- 반복 후에도 오류가 발생하면 작업을 종료

## 맵 입력 분할
- 맵의 입력은 스플릿 단위(inputSplit)로 분할
- 큰 데이터를 하나의 노드에서 처리하지 않고, 분할 및 병렬처리 하여 작업시간 단축
- 스플릿이 작으면 부하가 분산되어 성능을 높일 수 있지만, 너무 작으면 맵 작업의 개수가 증가하고 오버헤드가 증가하여 오히려 작업이 느려질 수 있음
- 따라서 작업에 따라 적절한 개수의 맵 작업을 생성해야 하며, 일반적으로 적절한 스플릿 크기는 HDFS 블록의 기본크기인 128MB

## 맵리듀스 작업의 종류
- 맵리듀스는 리듀서 작업이 있는 경우와 없는 경우로 나뉨
1. 리듀서가 없는 경우(Mapper Only)
    - 파일을 읽어서 바로 스는 작업의 경우 리듀서가 필요 없어 매퍼만 있는 작업이 됨
    - 원천 데이터를 읽어서 가공하고 바로 쓰는 경우.
    - 리듀서 작업이 없기 때문에 빠름
    - 매퍼의 수만큼 파일이 생성되므로 추가적인 파일 머지 작업이 필요할 수 있음
2. 리듀서가 하나인 경우
    - 모든 데이터의 정렬작업 같은 경우. 리듀서 하나로 모든 작업을 처리하므로 시간이 오래 걸림
3. 리듀서가 여러개인 경우 
    - 일반적인 집계 작업인 경우로, 리듀서의 수만큼 파일이 생성됨
    - HDFS의 부하를 방지하기 위해 추가적인 파일 머지 작업이 필요할 수 있음

